<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>measurement | Ju' Research and Life</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://juyujeng.github.io/researchlife/tags/measurement/><link crossorigin=anonymous href=/researchlife/assets/css/stylesheet.f60a790950768e0d7b2b06df792d7329394fed27df3fd67d681267ffe9e23ccb.css integrity="sha256-9gp5CVB2jg17KwbfeS1zKTlP7SffP9Z9aBJn/+niPMs=" rel="preload stylesheet" as=style><link rel=icon href=https://juyujeng.github.io/researchlife/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://juyujeng.github.io/researchlife/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://juyujeng.github.io/researchlife/favicon-32x32.png><link rel=apple-touch-icon href=https://juyujeng.github.io/researchlife/apple-touch-icon.png><link rel=mask-icon href=https://juyujeng.github.io/researchlife/safari-pinned-tab.svg><link rel=manifest href=/site.webmanifest><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://juyujeng.github.io/researchlife/tags/measurement/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+TC&family=Noto+Serif+TC:wght@500&display=swap" rel=stylesheet><script async src="https://www.googletagmanager.com/gtag/js?id=G-8XNMY2VF63"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8XNMY2VF63",{anonymize_ip:!1})}</script><meta property="og:title" content="measurement"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://juyujeng.github.io/researchlife/tags/measurement/"><meta name=twitter:card content="summary"><meta name=twitter:title content="measurement"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://juyujeng.github.io/researchlife/ accesskey=h title="Ju' Research & Life (Alt + H)"><img src=https://juyujeng.github.io/researchlife/apple-touch-icon.png alt aria-label=logo height=30>Ju' Research & Life</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://juyujeng.github.io/researchlife/about title="About Me"><span>About Me</span></a></li><li><a href=https://juyujeng.github.io/researchlife/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://juyujeng.github.io/researchlife/docs/ title=Document><span>Document</span></a></li><li><a href=https://juyujeng.github.io/researchlife/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://juyujeng.github.io/researchlife/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://juyujeng.github.io/researchlife/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>measurement</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>OT學生的同理等級：文獻閱讀心得</h2></header><div class=entry-content><p>OT學生的同理等級：文獻閱讀心得 興起搜尋了在OT領域當中有關同理心的研究，發現在2010年Brown等人有一篇挺有趣的研究。這個研究主要想要知道兩個問題
OT的學生同理心的程度怎麼樣？在大學的訓練又會對於同理心有什麼樣的影響？ 對於不同的病人，OT學生的關注（regard）程度會不會有所不同呢？ 為了回答這兩個問題，Brown等人（2010）利用兩個量表來進行研究，分別是[[Jefferson Scale of Empathy]] HP version，以及[[Medical Condition Regard Scale (MCRS)]]。前者是醫學領域很常見的同理心自評量表，由醫療人員自我評量覺得自己的同理程度如何，主要著重在認知同理，但同時也包含一些行為同理的題目。後者則是11題自評對於某一種類型的病人的關心或是願意治療對方的程度（題目如後）。實驗選擇讓學生評論五種病人，是常見的五種，範圍包含了生理、心理、發展的疾病，不過實際上OT會遇到的病人種類更多。這五種包含：
stroke traumatic brain injury cerebral palsy substance abuse depression 看前面的問題，本以為會是一個縱貫性的研究，但結果還只是一個橫斷式的研究，只是招募Monash University大學部的OT學生來填寫上述兩個量表。結果共有96名參與者（91%是女性），同時一、二、三年級的各佔19.6%、48.9%以及31.5%（沒有四年級）。
由於量表的分數作者認為算是ordinal scale，故都以無母數統計法來分析。
同理心是否有年級、性別差異？ 所有參與者的JSE分數中位數為115，過去其他的研究也差不多在這個分數附近（比115高一些），看來這間學校的OT學生有不錯的同理程度（自評）。 沒有發現有年級或是性別的差異。 經過比較多年的OT課程訓練並沒有增加，或是減少自評同理程度 但是因為男生數量很少，性別沒有差異的結果要有所保留。 是否對不同疾病的病人有不同的關注程度？ Friedman test結果發現，對於substance abuse病人的MCRS得分低於其他種病人，代表OT學生對於藥物濫用的病人較不關注 不同年級的學生對於同一種病人的關注程度不同，這個效果存在下列四種病人，但不包含depression - stroke - traumatic brain injury - cerebral palsy - substance abuse 不同性別的學生對於不同疾病的病人沒有不同的關注程度 心得 學校的訓練對於自評同理程度沒有影響。不過這個是cross section的研究，而非縱貫性的研究，還不能完全下這個結論。但是相較於對於不同類型的病人的關注程度，同理程度在不同年級之間沒有差異應該還是可以有這樣子的懷疑。 學校的訓練可能增加了對於不同疾病的知識，所以不同的年級之間對於同一個種類的疾病的病人關注程度不同是可以想見的。但是這篇的結果並沒有在這裡寫得太詳細，不確定知識變多之後，關注程度是變高還是變低 並沒有發現性別的同理程度差異，但如前面所言，9成都是女性，這個性別的差異很難比出來吧！ MCRS是一個有趣的量表，感覺有點像是自評哪一種病人比較好搞的。 文獻 Brown, T., Williams, B., Boyle, M., Molloy, A., McKenna, L., Molloy, L., & Lewis, B....</p></div><footer class=entry-footer><span title='2022-08-31 00:00:00 +0000 UTC'>August 31, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to OT學生的同理等級：文獻閱讀心得" href=https://juyujeng.github.io/researchlife/blog/research/ot%E5%AD%B8%E7%94%9F%E7%9A%84%E5%90%8C%E7%90%86%E7%AD%89%E7%B4%9A%E6%96%87%E7%8D%BB%E9%96%B1%E8%AE%80%E5%BF%83%E5%BE%97/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>如何區分工具是reflective model或是formative model</h2></header><div class=entry-content><p>要如何區分一個測量工具是reflective model還是formative model？根據Coltman等人（2008）所整理的資料，有6個可以考量的點。其中前三點是理論上的考量點，後三點是實務上考量點。這不只是在發展測驗時需要考量應該要發展符合哪一種模型的工具，同時也可以在發展過程或是事後檢驗發展好的工具是否符合原先預期的模型。
考量要點 reflective model formative model 構念的本質 測量的構念是自然存在的，例如像人格 測量的構念是被定義出來的，例如說初生兒測量的[[Apgar Score]] 測量題目和構念間的因果關係 構念是因，題目是果 題目是果，構念是因 用來測量構念的題目特性 題目間相關性很高，題目間的可替代性很高，就算拿掉其中幾題也不會影響到所要測量的構念 項間之間並沒有假設有高相關，題目的不可替換性高，增加或是減少題目可能會使得測量的構念改變 題目間的相關 間應該要有高相關係或是一致性。可以使用Cronbach alpha, average variance extracted, factor loadings來驗證 並未假設題目間的相關性。 題目與所測量的構念的前因、後果間的關係 題目和構念的前因後果之間的關係，應該要和構念跟它們的關係一致。（像是：內容效度、收歛效度、區辨效度） 題目跟構念的前因後果間的關係不一定和構念跟它們的關係相似。 測量誤差以及共線性 題目有測量誤差，但是構念沒有。而且假設題目的測量誤差之間是無關的。測量誤差可以在測量之後利用因素分析的方法在統計上消除。 題目沒有測量誤差，但是構念有（不過這裡叫做disturbance，和measurement error不同的概念）。disturbance沒辦法像reflective model一樣可以用統計方法來消除。而必須要在設計測驗時就想辦法。 因此，按照這個表格，若要判斷[[測量一般人的同理心量表]]是屬於哪一種model，可以按照這個表一一檢驗。
參考文獻 Coltman, T., Devinney, T. M., Midgley, D. F., & Venaik, S. (2008). Formative versus reflective measurement models: Two applications of formative measurement. Journal of Business Research, 13. https://doi.org/10.1016/j.jbusres.2008.01.013
[[coltmanFormativeReflectiveMeasurement2008]]</p></div><footer class=entry-footer><span title='2022-08-03 00:00:00 +0000 UTC'>August 3, 2022</span></footer><a class=entry-link aria-label="post link to 如何區分工具是reflective model或是formative model" href=https://juyujeng.github.io/researchlife/blog/research/%E5%A6%82%E4%BD%95%E5%8D%80%E5%88%86%E5%B7%A5%E5%85%B7%E6%98%AFreflective-model%E6%88%96%E6%98%AFformative-model/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>測量一般人的同理心量表</h2></header><div class=entry-content><p>測量一般人的同理心量表 同理心是一個複雜但是十分重要的能力，特別是對於經常需要處理人與人之間相處的工作尤其重要，例如醫療專業人員。近來更是連警察都被要求需要有同理心，稱呼別人要小心（新聞）。
先前回顧了許多測量醫療專業人員的同理能力高低的量表，但有沒有測量非醫療專業人員的工具呢？
我從scopus搜尋了幾個關鍵字，包含了empathy、measurement、tool、assessment、reliability、validity等，並在幾篇回顧性文章的幫助之下找到了不少測量非醫療專業人員的測量工具。其中絕大多是自陳式量表，用來評估填答者自身的同理心能力或是人格特質，少部份是認知測驗。
若是要評估他人的同理心的量表非常的稀少。目前只有看到有：
[[Other Dyadic Perspective-Taking scale]]：由伴侶評量感受到的另一伴的同理心 [[Perceived empathy in online community]]：由作答者評量在社群網路上感受到被社群同理的程度 [[Griffith Empathy Measure]]：由父母評量孩子可以同理他人的能力 評估他人的同理能力的量表非常的稀少這一點並不意外，畢竟一般人在生活中鮮有需要去評估他人同理心能力高低的時候。就算有，通常也只要自己在心裡面有個底就好，不需要實際上量化出來。除非像是伴侶接受伴侶治療時，也許治療師需要評估一下伴侶雙方對對方的感受時需要，又或者父母想要了解孩子的同理（心智）發展的情況，才需要將其量化。
因此，若要發展一般人使用的同理心評估量表，自評的看來已有不少現存工具。若要評他人的同理心能力，也許需要先想想使用的情境，畢竟機會真的不多。
測驗清單 table model as 模型, target as 目標對象, 測量方式 from #empathy & #measurement & #inventory & -#blog where forclinical != true sort file 參考文獻 主要
Hemmerdinger, J. M., Stoddart, S. D., & Lilford, R. J. (2007). A systematic review of tests of empathy in medicine. BMC Medical Education, 7(1), 24. https://doi.org/10.1186/1472-6920-7-24...</p></div><footer class=entry-footer><span title='2022-07-20 00:00:00 +0000 UTC'>July 20, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 測量一般人的同理心量表" href=https://juyujeng.github.io/researchlife/blog/research/%E6%B8%AC%E9%87%8F%E4%B8%80%E8%88%AC%E4%BA%BA%E7%9A%84%E5%90%8C%E7%90%86%E5%BF%83%E9%87%8F%E8%A1%A8/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>測量一般人的同理心量表是reflective or formative model</h2></header><div class=entry-content><p>測量一般人的同理心量表 先前整理了[[測量一般人的同理心量表]]，但這些量表是屬於reflective model或是formative model當時並沒有很詳細地去進行判斷。
根據Coltman等人（2008）[[coltmanFormativeReflectiveMeasurement2008]] 的整理，這兩種measurement model的差異可以從幾個地方來檢視（見[[如何區分工具是reflective model或是formative model]]）。因此，我也試著用這六點來檢視先前找到的15個測量工具。這六點可以分做理論上以及實務上考量的要點，而實務上的要點需要測驗的結果，若原始論文沒有提供，我也難以判斷。因此，這裡主要是以理論上考量要點做為判斷依據。
要測量的構念的本質是否自然形成或是人為定義出來的 所測量的項目（題目）與構念間的因果關係 測量的項目的特性（可替代性） 在實際判斷時，最主要還是考慮第2點，項目與構念之間的因果關係。
measurement model 例如，以[[Toronto Empathy Questionnaire]]裡面的題目為例：
I enjoy making other people feel better
這是一個自評的量表，自我評量認為自己的同理心是高或低。如果心中的假設是同理心高的人較樂意去幫助他人，那也就是說，是同理心這個能力或是特質影響到是否能夠感受到他人情緒的表現。從這個角度來看，這題目無疑是屬於reflective model。因為「我的行為」是受到「我的能力」或是特質所影響的。這樣子來看，所有的自評量表都是reflective model：
我的同理心 → 幫助他人行為頻率
不過，若是場景換成我們要去評論別人的同理心高低時，情況就複雜的多了。因為知人知面不知心，通常我們只從這個人的行為表現來看，他是否很常做出某些符合我們心中具有同理心的人的表現（例如很常關懷他人）。這時候助人行為與同理心的因果可以是：因為他很常幫助他人，所以我覺得這個人很有同理心。但也可以是因為這個人是有同理心的人，所以可以看到他很常幫助他人。
這樣看來，在評論他人的同理心高低時，似乎會有兩種measurement models都可以，端看研究者心中的假設，這樣子的感覺。然而，仔細想想，這兩種model所測量的潛在構念有些許的不同：
reflective model 這個人的同理心 → 我觀察到幫助他人行為頻率
formative model 我感覺到的這個人的同理心 → 我觀察到他幫助他人的行為頻率
因此，在評論他人的同理心高低時可能可以有兩種角度。
我找到的主要有三個測驗是評論他人的同理心
[[Perceived empathy in online community]]。這個題目都在問作答者感受到的感受，所以我覺得應該只有formative model [[Griffith Empathy Measure]]由父母來評量小孩的行為，可以由兩種角度來看。故我覺得可以是reflective或是formative。不過作者應該是認為該量表是reflective model，從分析的方法上來判斷的話。 另外還有[[Other Dyadic Perspective-Taking scale]]，這個我一直找不到題目，無法判斷。 測驗清單 table model as 模型, target as 目標對象, 測量方式 from #empathy & #measurement & #inventory & -#blog where forclinical !...</p></div><footer class=entry-footer><span title='2022-07-20 00:00:00 +0000 UTC'>July 20, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 測量一般人的同理心量表是reflective or formative model" href=https://juyujeng.github.io/researchlife/blog/research/%E6%B8%AC%E9%87%8F%E4%B8%80%E8%88%AC%E4%BA%BA%E7%9A%84%E5%90%8C%E7%90%86%E5%BF%83%E9%87%8F%E8%A1%A8%E6%98%AFreflective-or-formative-model/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>如何測量後設認知（metacognition）</h2></header><div class=entry-content><p>如何測量後設認知（metacognition） 後設認知的定義 如同前次[[metacognition the definition]]所整理，後設認知（[[metacognition]]）指的是對於認知歷程的監控歷程，並在臨床領域中進一步的推廣到對於自身以及他人的認知歷程的覺察與評價，同時可以利用這個覺察與評價的結果進一步的調整自己的行為策略。
我們可以看到某些研究的領域中，後設認知著重在於對自身認知歷程的覺察與評價，而某些領域中，強調的是整體的行為能否有效地進行調控。
後設認知的測量方法 目前常見的後設認知測量方法有三種，一種是面談（interview）中由訪談者評分，一種是自陳式的量表，而第三種則是認知測驗以及相關的指標參數的計算。
在我所回顧的文獻當中，認知測驗相關的研究最多，但是也最雜。因為在不同的認知心理學次領域當中針對不同的主題（例如：記憶、學習、知覺…）都各自有不同的實驗派典。也就是說，針對不同的後設認知所要監控或是覺察評價的目標，有不同的作業。而在這些不同的作業當中有共通可以使用的測量方式。我最後再來討論這個。先從面談以及自陳式量表開始。
訪談以及自陳式量表 面談以及自陳式量表的後設認知測量方法系出同門，根據Metacognitive Multi-Function Model (MMFM)，後設認知包含三方面的能力
Understanding one’s own mind Understanding of others’ mind Mastery（能夠利用對於個體心理表徵以及心理狀態執行有效策略來完成認知作業或是解決困難的能力） metacognition assessment scale (MAS) Semerari等人（2003）根據上述理論架構設計了一個訪談的評分表，三個能力各自有9 ~ 11題不等，每一題都是是非題，由訪談的治療師進行評分。不過當時Semerari等人只有報告了幾名case的資料，並沒有大規模施測的資料。
metacognition self-assessment scale 而根據同樣的理論架構，Pedone等人（2017）發展了[[Metacognition Self-Assessment Scale]]，是18題的自陳式5點量表用來測量個體的上述三面向的能力。就其因素分析的結果，作者歸納出四個因素：
self-self-reflexivity (monitoring and integration) differentiation and decentering understanding of other’s mind (self-other) regulation and control abilities (mastery) Pedone等人雖然在一個大型計畫中發展這個量表而有6000多筆的受測者資料，但並沒有進行相關的信效度分析。
後續Faustino等人（2021）將其翻譯為葡萄牙語版本，並進行了194個樣本的信效度研究。結果發現葡萄牙語版的因素結構和原版的因素結構相似，並有良好的內部一致性性度（ $\alpha = .88$）以及4週的再測信度。收歛效度良好，但沒有足夠的divergent validity。他們根據受測者自陳的結果將受測者分為一般組以及臨床診斷組（自陳有憂鬱、焦慮、注意力缺失…等相關症狀者），結果發現兩組人在understanding other’s mind上沒有顯著差異，其他的分向度以及總分都有差異。
short form Metacognitions questionnaire (MCQ-30) MCQ-30並非根據上述的MMFM架構而來。但理背後的理論也是認知後設認知是一種自我調節能力（Self-Regulatory Executive Function，S-REF； Wells, 2000; Wells & Matthews, 1994, 1996），而且是針對擔憂（WORRY）所進行的調控。...</p></div><footer class=entry-footer><span title='2021-11-23 00:00:00 +0000 UTC'>November 23, 2021</span></footer><a class=entry-link aria-label="post link to 如何測量後設認知（metacognition）" href=https://juyujeng.github.io/researchlife/docs/methods/summary-of-how-to-measure-metacognition/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>wisconsin card sorting研究心得</h2></header><div class=entry-content><p>wisconsin card sorting研究心得 [[Wisconsin Card Sorting Task]]（WCST）是一個很常用的神經心理測驗，最早是被用來作為思考彈性的測驗，但後來被發現可以用來評估腦傷程度。現在許多研究也使用它來做為認知彈性的測量工具。也有研究發現在自閉症、思覺失調症患者上都有表現較一般人差的情況1，而這兩種疾病的患者也都被認為有認知彈性缺乏的問題。
文獻中提到的缺點 雖然這個作業已經有長期使用的歷史，但是目前看來仍有些缺點。
首先是測驗相當複雜，所測量到的能力可能有很多個。作業表現的差可能的原因很多。有的研究者把這個作業當作是執行控制功能（executive function）的測驗工具，而不是單指認知彈性。但其實認知彈性有許多的定義，所以這一點雖然可以算是缺點，但也可以算是優點，因為認知彈性可能就是一個多能力交互作用才可以得到的表現。
另外測驗結果指標多元，但背後所對應的能力仍不確定。文獻中不同的研究者曾提出不同的計分方式，最常見的是total error（所有分類錯誤的卡片數量）、categories completed（完成的組數）、perseverative errors（延續使用舊有規則造成的錯誤）、failure to maintain set（無法連續正確分類）。有可能不同的指標所指涉的是不同的認知能力，又或者有些指標所測量到的不只一種能力。這樣看來，將這個作業歸為執行控制功能測量工具可能較合適，因為執行控制功能本身也是一個複雜的概念，包含多種能力在其中。
WCST的測驗規則變化是固定的，多次測量的結果可能會有練習效果或是穩定度的問題，但目前相關的研究結果並不一致。例如有研究發現1年後正常成人再測的練習效果很大1。但其他研究發現卻發現間隔9個月再測信度不錯，而且練習效果不大2。
WCST也有發展電腦化的測驗，但是電腦化測驗的心理計量特性研究發現，電腦化的版本和原先版本並不相同，不能夠共用常模34。
WCST心理計量驗證情況 我在scopus以及google scholar搜尋找尋相關的信效度研究
WCST有許多的版本，但多以128張卡片的研究為主，部份為64張卡片。前者為同樣的64張但進行兩次，需要花費較多的時間。此外也有修改版（去除掉同時可以符合2種以上規則分類的卡片）以及電腦化的版本，但這兩種版本的驗證研究還非常的稀少。
大部份的信效度驗證研究多為檢驗再測信度的研究，但是結果顯示WCST的再測信度結果在不同的研究間並不穩定。可能的原因有：
間隔時間，兩次測驗的間隔從9個月到2年不等。 WCST的作業表現指標眾多，不同指標再測相關係數有高低起伏。最近一篇研究5發現“nonperseverative errors” and “failure to maintain set”的一致性較低。 受測者大多是病人，早期多為腦傷，而近期多為思覺失調症患者。有可能他們的性質差異很大，表現也比較不穩定。 WCST有好的折半信度。今年有兩篇研究分別探討WCST以及修改版的WCST的折半信度，他們分別使用健康的年輕人以及神經受傷的住院病人，都得到良好的折半信度。
電腦版和非電腦版WCST的心理計量特性是不同的。有不只一篇的研究比較標準的WCST以及電腦化的版本，結果發現受測者的兩種版本測驗表現可能沒有顯著的差異，但是電腦化的測驗變異可能比較小。電腦版的表現變異較小的情況不只是在健康控制組，思覺失調症患者以及自閉症患者的樣本都有一樣的結果。
我的看法 WCST已經被用了數十年，本來我以為相關的心理計量特性研究應該相當完整。想不到真的仔細去找時才發現大家都用得很開心的作業不一定都有完整的信效度研究報告。電腦化的測驗可以節省許多施測者的麻煩，但想不到相關的常模並未完整建立。
回到定義，彈性指的是對於環境變化能夠產生適應的行為。所以測驗當中「變化」是重要的。但在這個測驗當中，變化是要在特定作答表現下才會出現的，如果達到條件，變化不會出現。有沒有辦法去調整變化的程度，檢驗不同變化情境下反應隨著變化程度不同而改變的程度呢？
Basso, Michael R., Natasha Lowery, Courtney Ghormley, and Robert A. Bornstein. “Practice Effects on the Wisconsin Card Sorting Test–64 Card Version Across 12 Months.” The Clinical Neuropsychologist 15, no. 4 (December 1, 2001): 471–78....</p></div><footer class=entry-footer><span title='2021-11-15 00:00:00 +0000 UTC'>November 15, 2021</span></footer><a class=entry-link aria-label="post link to wisconsin card sorting研究心得" href=https://juyujeng.github.io/researchlife/blog/research/wisconsin-card-sorting%E7%A0%94%E7%A9%B6%E5%BF%83%E5%BE%97/></a></article></main><footer class=footer><span>contact me @ <a href="mailto: juyujeng@gmail.com">juyujeng@gmail.com</a></span><br><span>&copy; 2023 <a href=https://juyujeng.github.io/researchlife/>Ju' Research and Life</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>