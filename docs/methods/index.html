<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>🧰 methods | Ju' Research and Life</title><meta name=keywords content><meta name=description content="documents of research methods"><meta name=author content><link rel=canonical href=https://juyujeng.github.io/researchlife/docs/methods/><link crossorigin=anonymous href=/researchlife/assets/css/stylesheet.2f07baab30a71d9683f2c8ceca6578ca69765571c4d7546141d5d7c174d94716.css integrity="sha256-Lwe6qzCnHZaD8sjOymV4yml2VXHE11RhQdXXwXTZRxY=" rel="preload stylesheet" as=style><link rel=icon href=https://juyujeng.github.io/researchlife/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://juyujeng.github.io/researchlife/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://juyujeng.github.io/researchlife/favicon-32x32.png><link rel=apple-touch-icon href=https://juyujeng.github.io/researchlife/apple-touch-icon.png><link rel=mask-icon href=https://juyujeng.github.io/researchlife/safari-pinned-tab.svg><link rel=manifest href=/site.webmanifest><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://juyujeng.github.io/researchlife/docs/methods/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+TC&family=Noto+Serif+TC:wght@500&display=swap" rel=stylesheet><script async src="https://www.googletagmanager.com/gtag/js?id=G-8XNMY2VF63"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8XNMY2VF63",{anonymize_ip:!1})}</script><meta property="og:title" content="🧰 methods"><meta property="og:description" content="documents of research methods"><meta property="og:type" content="website"><meta property="og:url" content="https://juyujeng.github.io/researchlife/docs/methods/"><meta name=twitter:card content="summary"><meta name=twitter:title content="🧰 methods"><meta name=twitter:description content="documents of research methods"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Docs","item":"https://juyujeng.github.io/researchlife/docs/"},{"@type":"ListItem","position":2,"name":"🧰 methods","item":"https://juyujeng.github.io/researchlife/docs/methods/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://juyujeng.github.io/researchlife/ accesskey=h title="Ju' Research & Life (Alt + H)"><img src=https://juyujeng.github.io/researchlife/apple-touch-icon.png alt aria-label=logo height=30>Ju' Research & Life</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://juyujeng.github.io/researchlife/about title="About Me"><span>About Me</span></a></li><li><a href=https://juyujeng.github.io/researchlife/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://juyujeng.github.io/researchlife/docs/ title=Document><span>Document</span></a></li><li><a href=https://juyujeng.github.io/researchlife/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://juyujeng.github.io/researchlife/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://juyujeng.github.io/researchlife/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>🧰 methods</h1><div class=post-description>documents of research methods</div></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://juyujeng.github.io/researchlife/docs/methods/images/compbdt.svg alt="diagnost result table"></figure><header class=entry-header><h2>compare two binary diagnostic tests</h2></header><div class=entry-content><p>如何比較兩個診斷方式的準確性？ 幾個可以比較的指標 sensitivity (Se) = 病人有病且可以被診斷出有病的機率
specificity (Sp) = 病人沒病且可以被診斷沒病的機率
positive predicted value (PPV) = 被診斷為有病而實際上真的有病的機率
negative predicted value (NPV) = 被診斷為沒病而實際上真的沒病的機率
可以使用的方法 統計方法 比較的指標 McNemar test sensitivity、specificity GEE PPV、NPV weighted generalized score PPV、NPV 如何計算 GEE 的計算很難，而且在使用上的結果比較不直觀。雖然說Leisenring等人（2000）的概念令我感到驚豔（原來還可以這樣子用哦！）。他們以疾病的狀態為依變項做logistic GEE。二分的診斷結果X、二分的診斷工具Z為兩個預測變項。就變成了 $$logit(D) = \beta_1 Z + \beta_2 X + \beta_3 ZX$$ X = 1時，Z的係數是否顯著代表了兩個診斷工具的PPV是否有顯著差異；而X = 0時Z的係數則是NPV的差異。 所以要比較NPV時就看$\beta_1$有沒有顯著，但是在比較PPV時則是要看$\beta_1 + \beta_3$，這個檢定就比較難做。
weighted generalized score是近期比較多人使用的。而這個指標在計算上也是在不同的文獻當中有許多的改進。幸好最近有人將這些方法寫成了R的套件，有和DTComPair和compbdt兩個。
不過最近（2022/10/18）我發現DTComPair在新版的R已經不支援了，可能要找舊版的R去安裝，或是希望作者可以有更新。目前可能暫時就剩下compbdt可以使用。
compbdt的使用 compbdt其實不是一個完整的套件，只有一個函式，可以在原始論文的補充資料當中獲得。
使用時需要輸入兩種診斷工具的診斷結果（見下表）
compbdt(s11 = s11, s10 = s10, s01 = s01, s00 = s00, r11 = r11, r10 = r10, r01 = r01, r00 = r00, alpha = ....</p></div><footer class=entry-footer><span title='2022-10-18 00:00:00 +0000 UTC'>October 18, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to compare two binary diagnostic tests" href=https://juyujeng.github.io/researchlife/docs/methods/compare-two-binary-diagnostic-tests/></a></article><article class=post-entry><header class=entry-header><h2>unitization problem and code reliability</h2></header><div class=entry-content><p>unitization problem 在進行文本的分析時通常需要先將文本轉編為可以分析的單位，而要如何決定文本當中的那一個段落是值得分析的過程就是unitization。以Empathic Communication Coding System (ECCS)的分析為例。如何決定哪一個溝通的橋段出現同理的時機，值得進一步去分析治療師同理回應能力就是unitization。
但是當有兩個以上的coders進行文本分析時，很有可能出現這些coders對同一個文本所辨識出來的分析單位（unit）對不上的情況，這就是一種unitization problem造成的後果。
有些文本的分析是直接以時間或是段落為單位，例如整段錄音（影）每30秒為一個單位，判斷這個單位內有沒有出現目標的行為。這種情況下就沒有什麼unitization problem。但有些文本的分析是以unit of meaning (Campbell et a., 2013）為單位，也就是要先事先定義好某些特定的目標，有出現才將該段落納入分析，像ECCS就是這樣子的例子。
那要怎麼解決不同的coders找到不同的units呢？Campbell等人（2013）提出一個方法，那就是讓研究的主持人（通常是對於該主題最瞭解的人）做為主要unit辨別者，其他的coders只在主持人所找到的units當中進行資料的分析以及分類。這樣子就只會有分類上的歧異，而不會有unitization problem。但大家都知道，主持人很忙，所以最少也要讓主持人主導訓練coders的任務，並且在分類規則上多加參與，以盡量減少unitization problem。
reliability of unitizing 目前針對unitization的過程進行信度或是一致性的指標似乎只有Guetzkow’s U。其他分類一致性的指標我覺得指標的目的都不全然符合。因為文本當中可能有一大堆片段都沒有被挑出來，這樣可以衝出許多不同coders都一致認為不算meaningful unit的資料點。因此只能從所有的coders都挑出來的units當中去計算信度。但這樣子畫出來的2 by 2 contingency table又會缺少雙方都認為不是的那一格。
Guetzkow’s U Guetzkow’s U則是針對已經找到的units數量上來計算兩個coders所找到的數量上是否一致。其公式如下：
$$U = \frac{O_1 - O_2}{O_1 + O_2}$$
其中$O_1$代表第一個coder找到的所有units數量，而$O_2$則是第二位coder找到的units數量。
這個方法假設，如果兩個coders的能力是相同的，那麼雙方找到的units數量的期望值應該會是相同的（為常數$h$）。
因此，$U$越接近0，應該兩個coders的unitizing越一致。
references Campbell, J. L., Quincy, C., Osserman, J., & Pedersen, O. K. (2013). Coding In-depth Semistructured Interviews: Problems of Unitization and Intercoder Reliability and Agreement. Sociological Methods & Research, 42(3), 294–320....</p></div><footer class=entry-footer><span title='2022-09-29 00:00:00 +0000 UTC'>September 29, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to unitization problem and code reliability" href=https://juyujeng.github.io/researchlife/docs/methods/unitization-problem-and-unitizing-reliability/></a></article><article class=post-entry><header class=entry-header><h2>Kirkpatrick model</h2></header><div class=entry-content><p>Kirkpatrick model常被用來評估介入或是學習課程的成效，主要從四個層面來評估
reaction 指的是對於參與的課程之反應，通常是評估學員參與課程之後有什麼感覺，是否喜歡，或是覺得該課程對於自己有沒有幫助等反應 learning 指學習到該課程所欲傳達的知識、技術、態度等的程度 behavior 指將課程中學習到的應用到生活或是職場等場景的程度 results 指的是課程或是訓練後目標成果的達成程度 這個模型可以說從一個人參與某個課程之後可能有所改變的各個層面都加以評估，對於評量一個課程或是介入是否有效果是很有幫助的。
不過，若是要應用到目前打算回顧的同理心介入文獻當中，似乎就不是那麼對題了。</p></div><footer class=entry-footer><span title='2022-02-16 00:00:00 +0000 UTC'>February 16, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to Kirkpatrick model" href=https://juyujeng.github.io/researchlife/docs/methods/kirkpatrick-model/></a></article><article class=post-entry><header class=entry-header><h2>如何測量後設認知（metacognition）</h2></header><div class=entry-content><p>如何測量後設認知（metacognition） 後設認知的定義 如同前次[[metacognition the definition]]所整理，後設認知（[[metacognition]]）指的是對於認知歷程的監控歷程，並在臨床領域中進一步的推廣到對於自身以及他人的認知歷程的覺察與評價，同時可以利用這個覺察與評價的結果進一步的調整自己的行為策略。
我們可以看到某些研究的領域中，後設認知著重在於對自身認知歷程的覺察與評價，而某些領域中，強調的是整體的行為能否有效地進行調控。
後設認知的測量方法 目前常見的後設認知測量方法有三種，一種是面談（interview）中由訪談者評分，一種是自陳式的量表，而第三種則是認知測驗以及相關的指標參數的計算。
在我所回顧的文獻當中，認知測驗相關的研究最多，但是也最雜。因為在不同的認知心理學次領域當中針對不同的主題（例如：記憶、學習、知覺…）都各自有不同的實驗派典。也就是說，針對不同的後設認知所要監控或是覺察評價的目標，有不同的作業。而在這些不同的作業當中有共通可以使用的測量方式。我最後再來討論這個。先從面談以及自陳式量表開始。
訪談以及自陳式量表 面談以及自陳式量表的後設認知測量方法系出同門，根據Metacognitive Multi-Function Model (MMFM)，後設認知包含三方面的能力
Understanding one’s own mind Understanding of others’ mind Mastery（能夠利用對於個體心理表徵以及心理狀態執行有效策略來完成認知作業或是解決困難的能力） metacognition assessment scale (MAS) Semerari等人（2003）根據上述理論架構設計了一個訪談的評分表，三個能力各自有9 ~ 11題不等，每一題都是是非題，由訪談的治療師進行評分。不過當時Semerari等人只有報告了幾名case的資料，並沒有大規模施測的資料。
metacognition self-assessment scale 而根據同樣的理論架構，Pedone等人（2017）發展了[[Metacognition Self-Assessment Scale]]，是18題的自陳式5點量表用來測量個體的上述三面向的能力。就其因素分析的結果，作者歸納出四個因素：
self-self-reflexivity (monitoring and integration) differentiation and decentering understanding of other’s mind (self-other) regulation and control abilities (mastery) Pedone等人雖然在一個大型計畫中發展這個量表而有6000多筆的受測者資料，但並沒有進行相關的信效度分析。
後續Faustino等人（2021）將其翻譯為葡萄牙語版本，並進行了194個樣本的信效度研究。結果發現葡萄牙語版的因素結構和原版的因素結構相似，並有良好的內部一致性性度（ $\alpha = .88$）以及4週的再測信度。收歛效度良好，但沒有足夠的divergent validity。他們根據受測者自陳的結果將受測者分為一般組以及臨床診斷組（自陳有憂鬱、焦慮、注意力缺失…等相關症狀者），結果發現兩組人在understanding other’s mind上沒有顯著差異，其他的分向度以及總分都有差異。
short form Metacognitions questionnaire (MCQ-30) MCQ-30並非根據上述的MMFM架構而來。但理背後的理論也是認知後設認知是一種自我調節能力（Self-Regulatory Executive Function，S-REF； Wells, 2000; Wells & Matthews, 1994, 1996），而且是針對擔憂（WORRY）所進行的調控。...</p></div><footer class=entry-footer><span title='2021-11-23 00:00:00 +0000 UTC'>November 23, 2021</span></footer><a class=entry-link aria-label="post link to 如何測量後設認知（metacognition）" href=https://juyujeng.github.io/researchlife/docs/methods/summary-of-how-to-measure-metacognition/></a></article></main><footer class=footer><span>contact me @ <a href="mailto: juyujeng@gmail.com">juyujeng@gmail.com</a></span><br><span>&copy; 2023 <a href=https://juyujeng.github.io/researchlife/>Ju' Research and Life</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>