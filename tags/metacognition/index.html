<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>metacognition | Ju' Research and Life</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://juyujeng.github.io/researchlife/tags/metacognition/><link crossorigin=anonymous href=/researchlife/assets/css/stylesheet.cb6161d21234b928031cf6aa795fd2bdad5c2483cefd0557b9eb0ed142628e25.css integrity="sha256-y2Fh0hI0uSgDHPaqeV/Sva1cJIPO/QVXuesO0UJijiU=" rel="preload stylesheet" as=style><link rel=icon href=https://juyujeng.github.io/researchlife/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://juyujeng.github.io/researchlife/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://juyujeng.github.io/researchlife/favicon-32x32.png><link rel=apple-touch-icon href=https://juyujeng.github.io/researchlife/apple-touch-icon.png><link rel=mask-icon href=https://juyujeng.github.io/researchlife/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://juyujeng.github.io/researchlife/tags/metacognition/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="metacognition"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://juyujeng.github.io/researchlife/tags/metacognition/"><meta name=twitter:card content="summary"><meta name=twitter:title content="metacognition"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://juyujeng.github.io/researchlife/ accesskey=h title="Ju' Research and Life (Alt + H)">Ju' Research and Life</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://juyujeng.github.io/researchlife/about title="About Me"><span>About Me</span></a></li><li><a href=https://juyujeng.github.io/researchlife/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://juyujeng.github.io/researchlife/docs/ title=Document><span>Document</span></a></li><li><a href=https://juyujeng.github.io/researchlife/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://juyujeng.github.io/researchlife/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://juyujeng.github.io/researchlife/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>metacognition</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>後設認知測量方法的思考</h2></header><div class=entry-content><p>後設認知（[[metacognition]]）有許多的定義，如[[metacognition the definition]]所摘要，這些不同的定義大致上與認知歷程的監控，又或是對於認知歷程的覺察以及評價有關。
如何測量後設認知能力是一個問題。目前對於後設認知有幾種測量的方法，包含了量表以及認知作業。雖然這些後設認知量表號稱要測量後設認知的能力，但以量表來測能力總不太能夠說服人。而過去若用認知作業來測量後設認知的能力，通常是以作業表現以及跟受測者的自我評價間的相關作為指標。這種作法有可能會受到受測者的作業表現所限制（在計算上），而且這兩者間的關係在不同的研究中也不穩定。雖然近來有利用信號偵測理論（[[signal detection theory]]）來計算後設認知能力的方法，不過這個新方法還需要更多相關的驗證。
Garfinkel等人（2015）1提出在進行內感覺覺察能力知研究時在測量上應該將之分為三個各自獨立的層次，他們的看法或可以提供思考後設認知如何測量時可能的方向。這三個層次為：
accuracy 指客觀行為表現上的好壞程度 sensibility 指主觀感覺的評價 awareness 指accuracy以及sensibility的關連性 從Garfinkel等人（2015）的觀點，利用量表、問卷等方法詢問所得的個體主觀認知自己的行為表現有多好、自己有多少信心程度等，都是自己對於自己的信念。知道自己做得有多好的程度才是覺察（awareness）。
這三個層次彼此獨立這一點是Garfinkel等人的假設。然而在他們所研究的資料中卻發現，accuracy較高的那一群人，他們的accuracy和awareness是顯著的正相關，但accuracy低的那群人則是無關。
究竟這三個層次之間的關係為何是未來可能可以進一步檢驗以及探討的問題。
Garfinkel, Sarah N., Anil K. Seth, Adam B. Barrett, Keisuke Suzuki, and Hugo D. Critchley. “Knowing Your Own Heart: Distinguishing Interoceptive Accuracy from Interoceptive Awareness.” Biological Psychology 104 (January 2015): 65–74. https://doi.org/10.1016/j.biopsycho.2014.11.004. ↩︎</p></div><footer class=entry-footer><span title='2021-11-25 00:00:00 +0000 UTC'>November 25, 2021</span></footer><a class=entry-link aria-label="post link to 後設認知測量方法的思考" href=https://juyujeng.github.io/researchlife/blog/research/metacognitioin-more-details-from-bodily-awareness/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>如何測量後設認知（metacognition）</h2></header><div class=entry-content><p>如何測量後設認知（metacognition） 後設認知的定義 如同前次[[metacognition the definition]]所整理，後設認知（[[metacognition]]）指的是對於認知歷程的監控歷程，並在臨床領域中進一步的推廣到對於自身以及他人的認知歷程的覺察與評價，同時可以利用這個覺察與評價的結果進一步的調整自己的行為策略。
我們可以看到某些研究的領域中，後設認知著重在於對自身認知歷程的覺察與評價，而某些領域中，強調的是整體的行為能否有效地進行調控。
後設認知的測量方法 目前常見的後設認知測量方法有三種，一種是面談（interview）中由訪談者評分，一種是自陳式的量表，而第三種則是認知測驗以及相關的指標參數的計算。
在我所回顧的文獻當中，認知測驗相關的研究最多，但是也最雜。因為在不同的認知心理學次領域當中針對不同的主題（例如：記憶、學習、知覺…）都各自有不同的實驗派典。也就是說，針對不同的後設認知所要監控或是覺察評價的目標，有不同的作業。而在這些不同的作業當中有共通可以使用的測量方式。我最後再來討論這個。先從面談以及自陳式量表開始。
訪談以及自陳式量表 面談以及自陳式量表的後設認知測量方法系出同門，根據Metacognitive Multi-Function Model (MMFM)，後設認知包含三方面的能力
Understanding one’s own mind Understanding of others’ mind Mastery（能夠利用對於個體心理表徵以及心理狀態執行有效策略來完成認知作業或是解決困難的能力） metacognition assessment scale (MAS) Semerari等人（2003）根據上述理論架構設計了一個訪談的評分表，三個能力各自有9 ~ 11題不等，每一題都是是非題，由訪談的治療師進行評分。不過當時Semerari等人只有報告了幾名case的資料，並沒有大規模施測的資料。
metacognition self-assessment scale 而根據同樣的理論架構，Pedone等人（2017）發展了[[Metacognition Self-Assessment Scale]]，是18題的自陳式5點量表用來測量個體的上述三面向的能力。就其因素分析的結果，作者歸納出四個因素：
self-self-reflexivity (monitoring and integration) differentiation and decentering understanding of other’s mind (self-other) regulation and control abilities (mastery) Pedone等人雖然在一個大型計畫中發展這個量表而有6000多筆的受測者資料，但並沒有進行相關的信效度分析。
後續Faustino等人（2021）將其翻譯為葡萄牙語版本，並進行了194個樣本的信效度研究。結果發現葡萄牙語版的因素結構和原版的因素結構相似，並有良好的內部一致性性度（ $\alpha = .88$）以及4週的再測信度。收歛效度良好，但沒有足夠的divergent validity。他們根據受測者自陳的結果將受測者分為一般組以及臨床診斷組（自陳有憂鬱、焦慮、注意力缺失…等相關症狀者），結果發現兩組人在understanding other’s mind上沒有顯著差異，其他的分向度以及總分都有差異。
short form Metacognitions questionnaire (MCQ-30) MCQ-30並非根據上述的MMFM架構而來。但理背後的理論也是認知後設認知是一種自我調節能力（Self-Regulatory Executive Function，S-REF； Wells, 2000; Wells & Matthews, 1994, 1996），而且是針對擔憂（WORRY）所進行的調控。...</p></div><footer class=entry-footer><span title='2021-11-23 00:00:00 +0000 UTC'>November 23, 2021</span></footer><a class=entry-link aria-label="post link to 如何測量後設認知（metacognition）" href=https://juyujeng.github.io/researchlife/blog/research/summary-of-how-to-measure-metacognition/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>metacognition: the definitions</h2></header><div class=entry-content><p>metacognition: the definitions [[metacognition]]中文翻作後設認知，是一個高階的認知功能。通常metacogition被稱為thinking of thinking，也就是對於思緒的思緒，是一種反思（reflection）的歷程。
在心理學的文獻當中是這樣子定義它的：
cognition about cognition Awareness and understanding of one’s own thought processes the ability to reflect on and monitor cognitive processes the ability to monitor and introspect upon cognitive performance the psychological structures, knowledge, events and processes that are involved in the control, modiﬁcation and interpretation of thinking itself the ability to recognize and reﬂect on mental states, both of oneself and others, as well as the ability to use mentalistic knowledge to tackle the difﬁculties of social life’ 在部份定義當中，後設認知是一種思考或是認知的歷程。...</p></div><footer class=entry-footer><span title='2021-11-19 00:00:00 +0000 UTC'>November 19, 2021</span></footer><a class=entry-link aria-label="post link to metacognition: the definitions" href=https://juyujeng.github.io/researchlife/blog/research/metacognition-the-definition/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Metacognition: the clinical definitions</h2></header><div class=entry-content><p>Metacognition: the clinical definitions 在[[metacognition the definition]]中我整理了幾個在文獻當中見到的[[metacognition]]的定義。雖然這些定義有些許的不同，但不脫對於自己的認知歷程的覺察監控以及控制，只是不同的領域可以專注的地方不太一樣，有的強調覺察監控的部份，有的則強調控制的部份。然而今天我在幾個臨床的研究當中發現，他們對於[[metacognition]]的範圍又再更大了。
後設認知所監控的，不只是自己的認知歷程？ 根據Dimaggio等人（2014），後設認知指的是對於自己或是他人心智狀態的辨認以及反思，也包含了利用這個心理知識應對困難的社交生活
而Pedone等人（2017）也認為後設認知是一個廣範的詞，用來指稱能夠理解以及反思自己以及他人的心智狀態的能力。
到了臨床的領域，後設認知的目標對象不再只是對於自己的認知歷程或是心智狀態，同時也包含了對於他人的心智狀態的覺察。這…不就包含了同理心嗎！
不過在閱讀了一下相關的理論架構之後，不難理解在臨床當中後設認知會有這樣子的延伸。因為對於他人認知歷程的無法掌握也會讓個體無法調整自己的行為，很容易造成社會互動的困難。
只是這種再擴充的理論架構讓後設認知包含的內容又更加的複雜。例如根據Metacognitive Multi-Function Model (MMFM)，後設認知包含以下各個能力
Understanding One’s Own Mind Identification (ID) 對於自己認知歷程的掌握能力 Relating variables (RV) 連結不同的心理狀態，以及心理狀態跟行為表現的能力 Differentiation (D) 區分內在心理表徵與現實的能力 Integration (I) 對於自己的心理狀態和認知歷程能有一致性的整合能力 Understanding of others’ mind (UOM) Identification Relating Variables Differentiation Integration is the ability to produce coherent descriptions of other people’s mental processes and states. Mastery能夠利用對於個體心理表徵以及心理狀態執行有效策略來完成認知作業或是解決困難的能力 這種複雜化的架構也許可以較完整描述以及預期精神疾病可能有的狀況，但在研究上也更加的困難，因為可能相關的影響因子太多。</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to Metacognition: the clinical definitions" href=https://juyujeng.github.io/researchlife/blog/research/metacognition-the-clinical-definitions/></a></article></main><footer class=footer><span>contact me @ <a href="mailto: juyujeng@gmail.com">juyujeng@gmail.com</a></span><br><span>&copy; 2022 <a href=https://juyujeng.github.io/researchlife/>Ju' Research and Life</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>