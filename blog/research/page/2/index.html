<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>🔬 Research | Ju' Research and Life</title><meta name=keywords content><meta name=description content="where to share my research experiences"><meta name=author content><link rel=canonical href=https://juyujeng.github.io/researchlife/blog/research/><link crossorigin=anonymous href=/researchlife/assets/css/stylesheet.2f07baab30a71d9683f2c8ceca6578ca69765571c4d7546141d5d7c174d94716.css integrity="sha256-Lwe6qzCnHZaD8sjOymV4yml2VXHE11RhQdXXwXTZRxY=" rel="preload stylesheet" as=style><link rel=icon href=https://juyujeng.github.io/researchlife/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://juyujeng.github.io/researchlife/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://juyujeng.github.io/researchlife/favicon-32x32.png><link rel=apple-touch-icon href=https://juyujeng.github.io/researchlife/apple-touch-icon.png><link rel=mask-icon href=https://juyujeng.github.io/researchlife/safari-pinned-tab.svg><link rel=manifest href=/site.webmanifest><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://juyujeng.github.io/researchlife/blog/research/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+TC&family=Noto+Serif+TC:wght@500&display=swap" rel=stylesheet><script async src="https://www.googletagmanager.com/gtag/js?id=G-8XNMY2VF63"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8XNMY2VF63",{anonymize_ip:!1})}</script><meta property="og:title" content="🔬 Research"><meta property="og:description" content="where to share my research experiences"><meta property="og:type" content="website"><meta property="og:url" content="https://juyujeng.github.io/researchlife/blog/research/"><meta name=twitter:card content="summary"><meta name=twitter:title content="🔬 Research"><meta name=twitter:description content="where to share my research experiences"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://juyujeng.github.io/researchlife/blog/"},{"@type":"ListItem","position":2,"name":"🔬 Research","item":"https://juyujeng.github.io/researchlife/blog/research/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://juyujeng.github.io/researchlife/ accesskey=h title="Ju' Research & Life (Alt + H)"><img src=https://juyujeng.github.io/researchlife/apple-touch-icon.png alt aria-label=logo height=30>Ju' Research & Life</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://juyujeng.github.io/researchlife/about title="About Me"><span>About Me</span></a></li><li><a href=https://juyujeng.github.io/researchlife/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://juyujeng.github.io/researchlife/docs/ title=Document><span>Document</span></a></li><li><a href=https://juyujeng.github.io/researchlife/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://juyujeng.github.io/researchlife/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://juyujeng.github.io/researchlife/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>🔬 Research</h1><div class=post-description>where to share my research experiences</div></header><article class=post-entry><header class=entry-header><h2>同理心課堂練習要素</h2></header><div class=entry-content><p>先前提到原先課堂的練習只用部份對話逐字稿練習起來有點空虛
經過討論之後決定將只有部份對話的內容擴充為一個有背景設定的完整情境
先準備好2~3個，確認這個方向之後再進行文本庫的擴充
練習用腳本必備資訊 病人的基本資訊 年紀、性別（50~60、男性為較常見的） 診斷 （中風和SCI為最常見的） 在對話發生的情境中應該已知道的相關能力評估結果（認知、動作、日常生活功能） 外觀、給人的印象、性格、興趣（營造較為具體，容易想像的練習例子，同時給予的回應也可以相對應做彈性的調整） 對話的情境 對話的主要目的 對話發生的時間點（第幾次的治療、剛開始還是中段或是該次治療要結束時） 要練習的同理主要目標 該腳本主要想要練習的目的。按照這個目標來挑選或是撰寫對話內容 對話的內容 同理的線索（因為是文字腳本，先以對話的內容為主，必要時可以描述相關的動作） 同理情境表現： 情緒 困難 衝突 建議的同理回應原則以及例句 可以在練習完成之後與學員討論，一開始先不要放出來 回應的層級，參考ECCS 未察覺同理線索或是沒有給予回應 敷衍應付病人，或是一般對話給予的基本應對語助詞 例如：「恩。」 對當下對話表面內容給予回應但未明確地掌握病人觀點。 例如：「看得出來你很不滿」。 掌握病人觀點給予回應，包含了掌握過程中的詢問以及推論過程 例如：「因為…○○☆，讓你覺得不舒服是不是？」 或是在基於正確掌握觀點的情境下：「我們一起來試試☰＠★好嗎？」 後續擴充方向 回應之後的延伸對話 類似像RPG，不同的回應會觸發不同的後續反應 應可以對應到前面的回應層級來進行設定 範例 基本資料 病人資料 年紀： 69 性別： male 診斷： 左側缺血性中風（ischaemic stroke），浴室跌倒，右手骨折。輕微腦震盪。 認知功能： 正常 行走功能： 可以自主行走，但緩慢，右腳跌倒也有受傷，較不靈光。 日常生活功能： 移動以及穿衣服、洗澡等需要兩手的工作需要他人的協助。 Brunnstrom stage: upper proximal: null distal: null lower: 5-6 外觀：臉色蒼白，五官端正，頭髮凌亂。身高約180，身材纖細。 語言： 國/台 照顧者：看護（醫院的） 對話情境 第一次治療將結束前，治療師在詢問病人目前生活的狀況最想要改善之處，要做為治療目標。病人在二週前缺血性中風，行動並不方便，但似乎不太喜歡坐輪椅移動。 需要同理的狀況 不滿的情緒十分強烈 練習目標 練習如何應對表達出強烈的負面情緒的病人。 對話內容 T：治療師 P：病人...</p></div><footer class=entry-footer><span title='2022-11-10 09:46:22 +0800 +0800'>November 10, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 同理心課堂練習要素" href=https://juyujeng.github.io/researchlife/blog/research/practice_script_for_empathy/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://juyujeng.github.io/researchlife/images/med%20situation%203.excalidraw.svg alt></figure><header class=entry-header><h2>同理課程的困難</h2></header><div class=entry-content><p>規畫的同理心訓練課程在經過幾次的試驗之後大致上已經完成
課程粗略可以分為兩個部份，一個是同理心相關的知識介紹，另一個則是同理心實務技巧的練習
知識的介紹這邊沒有什麼問題，而且對於表現同理心為什麼會是困難的一件事情我相信我可以解釋地很清楚
困難的是在同理心實務技巧的練習
需要掌握的原則和技巧說起來其實都不難
但是這些技巧的使用就像身體技能一般，光說不練是沒有辦法讓身體習慣怎麼進行的
雖然透過之前實習生的錄音逐字稿可以截取出讓學員們看著練習的腳本
但幾次的試教下來我覺得看著文字的腳本練習，效果感覺沒有很好
雖然說大家都可以給出不錯的回應，但也感覺得出來大家其實並沒有非常能融入腳本的情境當中
這種帶著半抽離感的情境，總覺得可能離現實很遙遠
會不會實際來拍攝練習題目的影片效果會比較好呢？</p></div><footer class=entry-footer><span title='2022-10-31 21:15:20 +0800 +0800'>October 31, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 同理課程的困難" href=https://juyujeng.github.io/researchlife/blog/research/class-practice/></a></article><article class=post-entry><header class=entry-header><h2>potential nonverbal cues</h2></header><div class=entry-content><p>list of potential nonverbal cues</p></div><footer class=entry-footer><span title='2022-10-25 00:00:00 +0000 UTC'>October 25, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to potential nonverbal cues" href=https://juyujeng.github.io/researchlife/blog/research/potential-nonverbal-cues/></a></article><article class=post-entry><header class=entry-header><h2>Relation between subdimensions of empathy</h2></header><div class=entry-content><p>常見的同理心的向度 同理心的定義中曾提到，同理心的的定義多元，目前普遍接受同理心是一個包含多元向度（多元能力）的概念（或是能力）。
在這樣子的看法底下，我很自然地認為，這些不同的次向度的能力應該彼此之間是正相關的，因為都被一個共通的潛在構念所影響（圖二左）。
同理心是一個包含多向度的潛在構念或是一個籠統名詞呢？ 不過，Klöckner等人（2022）的研究卻發現，認知上的同理（JSE測量）跟行為上的同理表現（以VR-CODES測量）只有部份相關。更明確地說，JSE的分數高低的差異，只在醫師（實習生）的非口語行為表現上看到差異，口語同理行為則和JSE分數高低無關。
如果這些不同的次向度之間的關係並不是那麼緊密的話，也許同理心比較像是一種籠統的名詞（collective term），將許多不同的能力籠統地括在一起說（圖二右）。這些不同的能力之間不必然有正相關。
如果是這樣子的話，那麼要測量同理心將會更加的困難，因為不同的能力之間如果不一定有關係的話，那麼就沒有辦法只測量其中一項能力而去推估其他能力，這樣就不同測那麼多不同的次能力；相反的，可能要測量許多不同的能力，才可以形成對於同理心能力的印象。
不過，Klöckner等人（2022）只有15個人的資料，樣本數其實很少，這個結果是否是穩定的還需要更多的研究。只是，現有的同理心測量，絕大多數都是自評的認知同理。要有更多探討不同的同理向度間的關係，可能還要有較有效的情緒同理、行為同理的測量工具出現。
參考文獻 Klöckner, C. C., Gerbase, M. W., Nendaz, M., Baroffio, A., & Junod, N. P. (2022). Relationship between self-reported cognitive and behavioural empathy among medical students. Patient Education and Counseling, 105(4), 895–901. https://doi.org/10.1016/j.pec.2021.07.053</p></div><footer class=entry-footer><span title='2022-09-23 00:00:00 +0000 UTC'>September 23, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to Relation between subdimensions of empathy" href=https://juyujeng.github.io/researchlife/blog/research/relation-between-subdimensions-of-empathy/></a></article><article class=post-entry><header class=entry-header><h2>同理的困難</h2></header><div class=entry-content><p>同理的困難 make other understand 要做到同理有許多的困難
要先體認到不同的人有不同的角度與觀點，所以會有不同的看法以及預期。 在互動的過程需要理解或是辨認出他人現在的想法或是感受是什麼？ 除了理解到他人現在的想法外，還要理解對方「為什麼」會這麼想。能夠從對方的觀點來思考。才可以知道衝突發生的徵結點。 在可以從對方的觀點來思考之後，你才有辦法選擇以及做出適當反應。因為你要考量到反應之後，對方可能有什麼樣的反應。 每一步，都需要假設性思考、推理的能力。這都不是簡單的事情，以下再進一步說明
知道每個人都是不一樣的 每個人都是不一樣的，每個人都知道，但卻很常忘掉。又或者是說，我們可能很常用其他的方法來解釋其他人和我們的不一樣。
我這邊的不一樣指的是觀點的不同。這個不同有兩種來源，一個是較長期穩定的，基於每個人的成長背景、知識，以及長期和這個世界互動後形成對於世界認識的基模或者是習慣，這些組合成我們看待世界的觀點，影響著我們對於看到的東西所做出的詮釋以及思考歷程。另一個是個人當下的狀態，情緒、身體狀況（例如身體某個部位在痛、昨晚沒睡飽），也會影響當下對世界的看法，以及如果和世界互動的選擇。如果用數學式來看的話，也許會是像這樣吧
$$現在看世界的觀點 = 長期養成的觀點 + 當下的狀態$$
基於上述理由，對於同樣的事情不同的人有著不同的觀點或是感受，是很正常的，因為每個人的背景知識不一樣，當下的身體狀況也可能不一樣。
就像是上圖中的第一格，兩個人從各自不同的觀點來看同一個事物，一邊看起來是9，而另一邊看起來是6。如果雙方不知道彼此的觀點有所不同，那麼很容易都認為對方應該也要看到和自己相同的數字。甚至在發現對方和自己看得不一樣時，會覺得對方一定是錯的，或是對方有問題，才會和自己不一樣。
知道其他人可能和自己不同，才保有雙方繼續互動下去的彈性，否則在發現對方所想的和自己心裡所想的有所不同時，先入為主的認為對方有問題，接下來如果需要雙方達成共識，是接近不可能的事情。
理解或是辨認出他人現在的想法或是感受 在明白每個人的觀點都可能有所不同之後，接下來便是要實際理解到底對方的想法是什麼？畢竟許多人是有經過社會化的，外顯出來的和內心所想的不一定會相同。而在醫療的領域當中，有時候會遇到的情況是病人受限於身體狀況，可能也很難將自己的想法或是感受表達地很清楚。有些時候需要藉由一些身體語言或是引導問答，才有辦法釐清。那才有辦法像圖中第2格一樣，掌握到對方從他的角度看到的數字，是6。
理解對方「為什麼」會這麼想 光是知道對方現在實際的想法或是感受，那只是同理的初步動作。去理解到對方「為什麼」會有這樣的想法或是感受，我認為才算是進到的同理的核心。因為這必須要跳出自己的思考的角度和框架，試著從別人的角度去思考。這需要一些抽象推理能力，或是想像力，才有辦法將自己想像為他人，用另一套看世界的方法來思考。
不過，若是自己曾有過切身經驗，也許會比較簡單，但也可能有反效果。因為若對方和自己在相似的經驗當中是依循著相同的思考模式的話，你可能便可以理解對方為什麼會這麼想。但，每個人在面對相同的事件是可能有不同的反應或是思考模式的。甚至是雖然有相同的反應，但思考模式是完全不同的。
因此，這個部份是同理過程當中相當重要，但也十分困難的一步。若跟對方沒有基本的認識，基本上是很難有辦法去理解到對方為什麼會有這樣子的想法或是感受，只能夠從自己過去的經驗或是知識來去做猜測（要冒著猜錯的風險）。
做出適當反應 如果做到了上一步，那麼便自然而然的可以去做出適當的反應。
就像是圖中第3格，我們理解到對方之所以會將數字看作是6，是因為他從他的角度來看就會是6。而且他似乎沒有注意到數字上有一條底線，顯示9可能才是這個數字的正確答案。
如果知道對方是因為角度的關係，並且可能忽略掉了細微的底線。這時可以邀請對方到我這邊來，並指出底線的存在。又或者是我幫對方將數字掉頭，讓他可以看清楚底線。如果再多考慮到對方受傷行動不便（我應該有畫得很明顯吧？），後面這個做法會是更好的做法。
當還沒有辦法完成上一步，理解對方為什麼會這麼想時，最好不要輕舉妄動，這時最佳的行為準則是想辦法獲得更多的訊息來幫助自己理解對方的思考模式。</p></div><footer class=entry-footer><span title='2022-09-14 00:00:00 +0000 UTC'>September 14, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 同理的困難" href=https://juyujeng.github.io/researchlife/blog/research/%E5%90%8C%E7%90%86%E7%9A%84%E5%9B%B0%E9%9B%A3/></a></article><article class=post-entry><header class=entry-header><h2>OT學生的同理等級：文獻閱讀心得 2</h2></header><div class=entry-content><p>OT學生的同理等級：文獻閱讀心得 2 繼昨天看到的那篇Brown等人（2010）的文章後，今天看到一篇非常類似的文章。Serrada-Tejeda等人（2022）在西班牙的大學中等於是重覆了這個研究，他們廣發量表（[[Jefferson Scale of Empathy]]以及[[interpersonal reactivity inventory]]，這兩個都是常見的自評同理心量表），同樣以橫斷性研究的方式來檢驗大學四年的OT訓練是否會影響OT學生們的自評同理程度。
不過這次Serrada-Tejeda等人有221名有效樣本，比起Brown他們只有92位真得是好太多了。而且四個年級的學生都有（一到四年級分別有71、54、46、50人）。不過大部份仍然是女性（88.2％）。
Serrada-Tejeda他們的結果和Brown一樣，四個年級的學生的自評同理心並沒有差異，而且得分和過去文獻中回報的比起來，這個大學的OT學生的自評同理程度算是高的。
而與Brown等人的研究不同的是，這次Serrada-Tejeda他們有發現性別的差異，女性自評同理程度比較高。但這並不是新聞，許多其他的研究其實都有發現女性的同理心分數通常比男性高。Brown等人的研究沒有得到這個結果應該是人太少吧。
這篇研究的分析結果比起Brown他們寫得再多了一點點，至少有附上表格，可以比較清楚的看到四個年級的得分。
心得與發想 連續看到兩篇OT學生的學校訓練年資與自評同理程度無關的文章，會有這種結果其實有三種可能。第一個可能是這些訓練無助於同理心的增長；而第二種可能是學校訓練有用，但使用的測量工具測量不到學校訓練所增進的同理心；而第三種就是訓練無助同理心，而測量工具也測不到同理心。
第一種可能其實挺有可能的，畢竟主要的學校訓練和治療相關的專業知識比較有關係，同理心相關技巧不一定有在課程之中，文獻當中也沒有詳細說明。
第二種可能則是工具的問題，雖然說兩篇研究都是用目前常見的同理心自評量表，但其實仔細看題目，實在是會有點問號，像是JSE當中有一題：
I believe that emotion has no place in the treatment of medical illness
這個像是在測量醫事人員本身的信念，而不是能力。或是像另一題，同樣對於是否能測量到同理心打一個問號：
I have a good sense of humor that I think contributes to a better clinical outcome
因此，如果有更適合的工具可以使用的話，也許可以試著在台灣也來做一個調查試試看。而且這個調查若同時可以比較醫學院的其他科系，同時看看不同的醫學院內科系訓練對於學生們的同理心是否有所幫助，會是很有趣的議題。因為目前國外就已經有用JSE在不同科系進行過研究，有的有發現會隨著訓練年資同理心上升，而有的發現隨著訓練年資同理心下降。也許不同科系的訓練真的有所不同。例如工作上面和病人接觸時間較短的醫技系、藥學系的訓練，也許真的就和其他跟病人接觸時間較長的科系如護理系、醫學系，所強調同理心的程度不一樣，訓練也就不一樣。
文獻 Brown, T., Williams, B., Boyle, M., Molloy, A., McKenna, L., Molloy, L., & Lewis, B. (2010). Levels of empathy in undergraduate occupational therapy students....</p></div><footer class=entry-footer><span title='2022-09-01 00:00:00 +0000 UTC'>September 1, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to OT學生的同理等級：文獻閱讀心得 2" href=https://juyujeng.github.io/researchlife/blog/research/ot%E5%AD%B8%E7%94%9F%E7%9A%84%E5%90%8C%E7%90%86%E7%AD%89%E7%B4%9A%E6%96%87%E7%8D%BB%E9%96%B1%E8%AE%80%E5%BF%83%E5%BE%97-2/></a></article><article class=post-entry><header class=entry-header><h2>glmmTMB vs. GLMMadaptive</h2></header><div class=entry-content><p>glmmTMB vs. GLMMadaptive 記錄一下分析資料時使用glmmTMB以及GLMMadaptive的心得
glmmTMB GLMMadaptive 估計方法 Laplace approximation adaptive Gauss-Hermite quadrature 預測值 可以進行單純count part預測、zero part預測，以及兩部份模型加起來的期望值預測 沒辦法只進行count part預測，只能做zero part預測，以及兩部份模型加起來的期望值預測 估計方法的差異在本次zero-inflated model使用過程中有很大的使用經驗差異。glmmTMB比較常出現convergent problem，而GLMMadaptive幾乎沒有。根據glmmTMB的troubleshooting說明，會出現問題主要是和random effect有關，如果拿掉zero part random intercept就不會再跳出錯誤訊息了。而根據GLMMadaptive做的模型比較，有沒有zero part random intercept其實沒有顯著的差異。因此如果不強求一定要納入zero part random intercept，兩個packages的結果是一致的。不過如果一定要納入zero part random intercept，那就只能使用GLMMadaptive才不會有錯誤警告出現。
兩個套件的另一個差異是在進行預測（predict）時，glmmTMB可以只根據count part的結果進行預測，而GLMMadaptive不行。會有這個需求是因為很常只有count part的預測變項有顯著的結果，但是zero part沒有顯著的預測變項，因此若只想要看count part的預測線時，GLMMadaptive沒辦法給我這個結果1。
文獻上討論Laplace approximation和adaptive Gauss-Hermite quadrature哪一種估計方法比較準的有好幾篇，我大概看了一下他們的結論，其實不同研究的結果並不一致2。
另一個使用上的差異是在安裝上，GLMMadaptive安裝比較沒有什麼問題。但是glmmTMB因為還需要TMB，有時候在更新套件時會有版本不一致的情況，有點小困擾。
也許emmeans::qdgr()可以，但需要試試看 ↩︎
不過glmmTMB的作者在他的網頁上提到，Gauss-Hermite quadrature比Laplace approximation還要準確，但是估計速度比較慢（但在我的資料感覺不出來），而且random effect的數量上限制比較多。 ↩︎</p></div><footer class=entry-footer><span title='2022-08-31 00:00:00 +0000 UTC'>August 31, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to glmmTMB vs. GLMMadaptive" href=https://juyujeng.github.io/researchlife/blog/research/glmmtmb-vs.-glmmadaptive/></a></article><article class=post-entry><header class=entry-header><h2>OT學生的同理等級：文獻閱讀心得</h2></header><div class=entry-content><p>OT學生的同理等級：文獻閱讀心得 興起搜尋了在OT領域當中有關同理心的研究，發現在2010年Brown等人有一篇挺有趣的研究。這個研究主要想要知道兩個問題
OT的學生同理心的程度怎麼樣？在大學的訓練又會對於同理心有什麼樣的影響？ 對於不同的病人，OT學生的關注（regard）程度會不會有所不同呢？ 為了回答這兩個問題，Brown等人（2010）利用兩個量表來進行研究，分別是[[Jefferson Scale of Empathy]] HP version，以及[[Medical Condition Regard Scale (MCRS)]]。前者是醫學領域很常見的同理心自評量表，由醫療人員自我評量覺得自己的同理程度如何，主要著重在認知同理，但同時也包含一些行為同理的題目。後者則是11題自評對於某一種類型的病人的關心或是願意治療對方的程度（題目如後）。實驗選擇讓學生評論五種病人，是常見的五種，範圍包含了生理、心理、發展的疾病，不過實際上OT會遇到的病人種類更多。這五種包含：
stroke traumatic brain injury cerebral palsy substance abuse depression 看前面的問題，本以為會是一個縱貫性的研究，但結果還只是一個橫斷式的研究，只是招募Monash University大學部的OT學生來填寫上述兩個量表。結果共有96名參與者（91%是女性），同時一、二、三年級的各佔19.6%、48.9%以及31.5%（沒有四年級）。
由於量表的分數作者認為算是ordinal scale，故都以無母數統計法來分析。
同理心是否有年級、性別差異？ 所有參與者的JSE分數中位數為115，過去其他的研究也差不多在這個分數附近（比115高一些），看來這間學校的OT學生有不錯的同理程度（自評）。 沒有發現有年級或是性別的差異。 經過比較多年的OT課程訓練並沒有增加，或是減少自評同理程度 但是因為男生數量很少，性別沒有差異的結果要有所保留。 是否對不同疾病的病人有不同的關注程度？ Friedman test結果發現，對於substance abuse病人的MCRS得分低於其他種病人，代表OT學生對於藥物濫用的病人較不關注 不同年級的學生對於同一種病人的關注程度不同，這個效果存在下列四種病人，但不包含depression - stroke - traumatic brain injury - cerebral palsy - substance abuse 不同性別的學生對於不同疾病的病人沒有不同的關注程度 心得 學校的訓練對於自評同理程度沒有影響。不過這個是cross section的研究，而非縱貫性的研究，還不能完全下這個結論。但是相較於對於不同類型的病人的關注程度，同理程度在不同年級之間沒有差異應該還是可以有這樣子的懷疑。 學校的訓練可能增加了對於不同疾病的知識，所以不同的年級之間對於同一個種類的疾病的病人關注程度不同是可以想見的。但是這篇的結果並沒有在這裡寫得太詳細，不確定知識變多之後，關注程度是變高還是變低 並沒有發現性別的同理程度差異，但如前面所言，9成都是女性，這個性別的差異很難比出來吧！ MCRS是一個有趣的量表，感覺有點像是自評哪一種病人比較好搞的。 文獻 Brown, T., Williams, B., Boyle, M., Molloy, A., McKenna, L., Molloy, L., & Lewis, B....</p></div><footer class=entry-footer><span title='2022-08-31 00:00:00 +0000 UTC'>August 31, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to OT學生的同理等級：文獻閱讀心得" href=https://juyujeng.github.io/researchlife/blog/research/ot%E5%AD%B8%E7%94%9F%E7%9A%84%E5%90%8C%E7%90%86%E7%AD%89%E7%B4%9A%E6%96%87%E7%8D%BB%E9%96%B1%E8%AE%80%E5%BF%83%E5%BE%97/></a></article><article class=post-entry><header class=entry-header><h2>如何區分工具是reflective model或是formative model</h2></header><div class=entry-content><p>要如何區分一個測量工具是reflective model還是formative model？根據Coltman等人（2008）所整理的資料，有6個可以考量的點。其中前三點是理論上的考量點，後三點是實務上考量點。這不只是在發展測驗時需要考量應該要發展符合哪一種模型的工具，同時也可以在發展過程或是事後檢驗發展好的工具是否符合原先預期的模型。
考量要點 reflective model formative model 構念的本質 測量的構念是自然存在的，例如像人格 測量的構念是被定義出來的，例如說初生兒測量的[[Apgar Score]] 測量題目和構念間的因果關係 構念是因，題目是果 題目是果，構念是因 用來測量構念的題目特性 題目間相關性很高，題目間的可替代性很高，就算拿掉其中幾題也不會影響到所要測量的構念 項間之間並沒有假設有高相關，題目的不可替換性高，增加或是減少題目可能會使得測量的構念改變 題目間的相關 間應該要有高相關係或是一致性。可以使用Cronbach alpha, average variance extracted, factor loadings來驗證 並未假設題目間的相關性。 題目與所測量的構念的前因、後果間的關係 題目和構念的前因後果之間的關係，應該要和構念跟它們的關係一致。（像是：內容效度、收歛效度、區辨效度） 題目跟構念的前因後果間的關係不一定和構念跟它們的關係相似。 測量誤差以及共線性 題目有測量誤差，但是構念沒有。而且假設題目的測量誤差之間是無關的。測量誤差可以在測量之後利用因素分析的方法在統計上消除。 題目沒有測量誤差，但是構念有（不過這裡叫做disturbance，和measurement error不同的概念）。disturbance沒辦法像reflective model一樣可以用統計方法來消除。而必須要在設計測驗時就想辦法。 因此，按照這個表格，若要判斷[[測量一般人的同理心量表]]是屬於哪一種model，可以按照這個表一一檢驗。
參考文獻 Coltman, T., Devinney, T. M., Midgley, D. F., & Venaik, S. (2008). Formative versus reflective measurement models: Two applications of formative measurement. Journal of Business Research, 13. https://doi.org/10.1016/j.jbusres.2008.01.013
[[coltmanFormativeReflectiveMeasurement2008]]</p></div><footer class=entry-footer><span title='2022-08-03 00:00:00 +0000 UTC'>August 3, 2022</span></footer><a class=entry-link aria-label="post link to 如何區分工具是reflective model或是formative model" href=https://juyujeng.github.io/researchlife/blog/research/%E5%A6%82%E4%BD%95%E5%8D%80%E5%88%86%E5%B7%A5%E5%85%B7%E6%98%AFreflective-model%E6%88%96%E6%98%AFformative-model/></a></article><article class=post-entry><header class=entry-header><h2>英文口說練習迴饋紀錄與心得 0801</h2></header><div class=entry-content><p>謝老師提供的福利，英文老師的一對一教學。我選擇了未來很有機會必須要做的英文口頭報告/授課的練習。我使用近來所準備的同理心教學投影片來進行這次的口頭報告。
我發現使用另外一個語言來說同一個投影片時，投影片之間邏輯連貫若沒有做好，更容易卡住，算是練習的意外收穫。
迴饋
某些字詞發音不完整或是錯誤，可能造成聽眾的誤會。特別是長音節的單字 （例如：satisfaction竟然唸成satisfication） 有些錯誤過了就算了，一直想要糾正自己反而會影響聽眾的感受 （例如：某個地方時態一直沒講對，2次就好，不要一直想要講對而一直重講） 快慢節奏的掌握。某些不是重點的地方應加速，重點處才放慢。 這個應該不只是英文的問題。中文的部份在舉例時也講太久，這個應該是投影片的內容需要摘要重點說明就好。不重要的地方不要講太細了。</p></div><footer class=entry-footer><span title='2022-08-01 00:00:00 +0000 UTC'>August 1, 2022</span></footer><a class=entry-link aria-label="post link to 英文口說練習迴饋紀錄與心得 0801" href=https://juyujeng.github.io/researchlife/blog/research/%E8%8B%B1%E6%96%87%E5%8F%A3%E8%AA%AA%E7%B7%B4%E7%BF%92%E8%BF%B4%E9%A5%8B%E7%B4%80%E9%8C%84%E8%88%87%E5%BF%83%E5%BE%97-0801/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://juyujeng.github.io/researchlife/blog/research/>«&nbsp;Prev&nbsp;</a>
<a class=next href=https://juyujeng.github.io/researchlife/blog/research/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>contact me @ <a href="mailto: juyujeng@gmail.com">juyujeng@gmail.com</a></span><br><span>&copy; 2023 <a href=https://juyujeng.github.io/researchlife/>Ju' Research and Life</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>