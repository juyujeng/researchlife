<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>🔬 Research | Ju' Research and Life</title><meta name=keywords content><meta name=description content="where to share my research experiences"><meta name=author content><link rel=canonical href=https://juyujeng.github.io/researchlife/blog/research/><link crossorigin=anonymous href=/researchlife/assets/css/stylesheet.cb6161d21234b928031cf6aa795fd2bdad5c2483cefd0557b9eb0ed142628e25.css integrity="sha256-y2Fh0hI0uSgDHPaqeV/Sva1cJIPO/QVXuesO0UJijiU=" rel="preload stylesheet" as=style><link rel=icon href=https://juyujeng.github.io/researchlife/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://juyujeng.github.io/researchlife/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://juyujeng.github.io/researchlife/favicon-32x32.png><link rel=apple-touch-icon href=https://juyujeng.github.io/researchlife/apple-touch-icon.png><link rel=mask-icon href=https://juyujeng.github.io/researchlife/safari-pinned-tab.svg><link rel=manifest href=/site.webmanifest><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://juyujeng.github.io/researchlife/blog/research/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-8XNMY2VF63"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8XNMY2VF63",{anonymize_ip:!1})}</script><meta property="og:title" content="🔬 Research"><meta property="og:description" content="where to share my research experiences"><meta property="og:type" content="website"><meta property="og:url" content="https://juyujeng.github.io/researchlife/blog/research/"><meta name=twitter:card content="summary"><meta name=twitter:title content="🔬 Research"><meta name=twitter:description content="where to share my research experiences"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://juyujeng.github.io/researchlife/blog/"},{"@type":"ListItem","position":2,"name":"🔬 Research","item":"https://juyujeng.github.io/researchlife/blog/research/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://juyujeng.github.io/researchlife/ accesskey=h title="Ju' Research & Life (Alt + H)"><img src=https://juyujeng.github.io/researchlife/apple-touch-icon.png alt aria-label=logo height=30>Ju' Research & Life</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://juyujeng.github.io/researchlife/about title="About Me"><span>About Me</span></a></li><li><a href=https://juyujeng.github.io/researchlife/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://juyujeng.github.io/researchlife/docs/ title=Document><span>Document</span></a></li><li><a href=https://juyujeng.github.io/researchlife/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://juyujeng.github.io/researchlife/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://juyujeng.github.io/researchlife/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>🔬 Research</h1><div class=post-description>where to share my research experiences</div></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://juyujeng.github.io/researchlife/images/empathy_cycle.png alt></figure><header class=entry-header><h2>Empathycycle</h2></header><div class=entry-content><p>Barrett-Lennard的老文章，討論同理的歷程。
同理的5步驟 在這個文章當中，同理的歷程包含5步驟
同理者（Em）主動注意到被同理者（Ex）自我表露的訊息（經驗、期待、希望、或是相信同理者能有所回應） 同理者覺察或是感受到了被同理者所直接或是間接傳達的，並在自己內在形成理解 同理者向被同理者以某種溝通的方式表達自己所覺察感受到的經驗 被同理者接收到了同理者的回應，並感受到同理者傳遞的某種程度的理解 被同理者繼續進行自我表露，其中也包含了對於同理者回應的迴饋，可能包含兩種類型 對同理者回應的內容（第3步驟中）的確認或是修正 感受到了同理者的同理建立了關係 如果被同理者接著繼續進行自我表露，並有新的訊息產生，那麼便會再回到第2步驟，否則便完成了一次同理的歷程。 在上述步驟中，第3~5都涉及了同理心的運作，但是運作的對象和內容是不同的，Barrett-Lennard將其分作三個階段。
第一階段：這個同理心是在同理者的內在運作的，同理者達到理解、共嗚的內在歷程 第二階段：這個同理心是同理者試著表達，將理解到的與被同理者溝通 第三階段：這個同理心是被同理者感到被同理 Barrett-Lennard將第三階段也加入在同理的歷程當中，我想是因為在心理治療的過程當中，治療師與個案雙方都是不可或缺的。在其他領域是否要加入或許可以討論。若只從治療師的角度來看整個歷程的話，第4步應該要跟第5步結合，進行被同理者是否感受到同理的確認。
這個歷程值得參考！
references Barrett-Lennard, G. T. (1981). The empathy cycle: Refinement of a nuclear concept. Journal of Counseling Psychology, 28(2), 91–100. https://doi.org/10.1037/0022-0167.28.2.91</p></div><footer class=entry-footer><span title='2023-01-11 11:43:59 +0800 +0800'>January 11, 2023</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to Empathycycle" href=https://juyujeng.github.io/researchlife/blog/research/empathycycle/></a></article><article class=post-entry><header class=entry-header><h2>OT_empathy</h2></header><div class=entry-content><p>文獻中醫病關係中的同理 同理心的定義多元。在不同的領域中因為各領域所強調的面向不同而有不同的定義。而在醫病相關的領域當中，同理心較強調「認知」以及「行為」兩個面向。認知的面向主要是指能夠理解他人的感受、想法、觀點的能力，這是一種認知功能。而在行為的面向主要是指能夠與他人溝通、表達理解的能力。
同理心被視為能夠有助於醫病的關係與溝通，根據Mercer & Reynolds (2002) 的整理，同理心應該有助於
提供有效的溝通，以理解病人的感受與需求 賦能（empower），幫助病人學習、有效地應對生活環境 減輕或是解決病人的問題 故，Mercer & Reynolds (2002) 回顧醫病情境當中同理心的定義，認為同理心是一個多面向的概念，其能力涉及：
(a) understand the patient’s situation, perspective and feelings (and their attached meanings);
(b) to communicate that understanding and check its accuracy; and,
(c) to act on that understanding with the patient in a helpful (therapeutic) way.
而Hojat等人（2002）同樣也定義醫病關係當中的同理心：
a cognitive attribute that involves an ability to understand the patient’s inner experiences and perspective and a capability to communicate this understanding....</p></div><footer class=entry-footer><span title='2023-01-10 10:57:46 +0800 +0800'>January 10, 2023</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to OT_empathy" href=https://juyujeng.github.io/researchlife/blog/research/ot_empathy/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://juyujeng.github.io/researchlife/blog/research/images/OTresponselevel.png alt></figure><header class=entry-header><h2>OT 同理回應等級以及訓練效果評估初想</h2></header><div class=entry-content><p>同理回應等級 已有的同理回應等級 在醫療上，根據empathic communication coding system (ECCS) 可以將治療師（醫師）的回應等級分為6個層級
不過並非層級越高就對於病人是越好的，不能以層次排序來衡量同理能力的高低
levels description example level 0 denial “Do you have any other medical problems?” level 1 Perfunctory Recognition “Hmm” level 2 Implicit recognition “Do you only have trouble with liquids during mealtimes?” level 3 Acknowledgement “We’re gonna do our best.” level 4 Acknowledgement with pursuit “We want to do everything we can to get you back to where you can have a good quality of life....</p></div><footer class=entry-footer><span title='2022-11-16 14:48:51 +0800 +0800'>November 16, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to OT 同理回應等級以及訓練效果評估初想" href=https://juyujeng.github.io/researchlife/blog/research/ot-response-level/></a></article><article class=post-entry><header class=entry-header><h2>同理心課堂練習要素</h2></header><div class=entry-content><p>先前提到原先課堂的練習只用部份對話逐字稿練習起來有點空虛
經過討論之後決定將只有部份對話的內容擴充為一個有背景設定的完整情境
先準備好2~3個，確認這個方向之後再進行文本庫的擴充
練習用腳本必備資訊 病人的基本資訊 年紀、性別（50~60、男性為較常見的） 診斷 （中風和SCI為最常見的） 在對話發生的情境中應該已知道的相關能力評估結果（認知、動作、日常生活功能） 外觀、給人的印象、性格、興趣（營造較為具體，容易想像的練習例子，同時給予的回應也可以相對應做彈性的調整） 對話的情境 對話的主要目的 對話發生的時間點（第幾次的治療、剛開始還是中段或是該次治療要結束時） 要練習的同理主要目標 該腳本主要想要練習的目的。按照這個目標來挑選或是撰寫對話內容 對話的內容 同理的線索（因為是文字腳本，先以對話的內容為主，必要時可以描述相關的動作） 同理情境表現： 情緒 困難 衝突 建議的同理回應原則以及例句 可以在練習完成之後與學員討論，一開始先不要放出來 回應的層級，參考ECCS 未察覺同理線索或是沒有給予回應 敷衍應付病人，或是一般對話給予的基本應對語助詞 例如：「恩。」 對當下對話表面內容給予回應但未明確地掌握病人觀點。 例如：「看得出來你很不滿」。 掌握病人觀點給予回應，包含了掌握過程中的詢問以及推論過程 例如：「因為…○○☆，讓你覺得不舒服是不是？」 或是在基於正確掌握觀點的情境下：「我們一起來試試☰＠★好嗎？」 後續擴充方向 回應之後的延伸對話 類似像RPG，不同的回應會觸發不同的後續反應 應可以對應到前面的回應層級來進行設定 範例 基本資料 病人資料 年紀： 69 性別： male 診斷： 左側缺血性中風（ischaemic stroke），浴室跌倒，右手骨折。輕微腦震盪。 認知功能： 正常 行走功能： 可以自主行走，但緩慢，右腳跌倒也有受傷，較不靈光。 日常生活功能： 移動以及穿衣服、洗澡等需要兩手的工作需要他人的協助。 Brunnstrom stage: upper proximal: null distal: null lower: 5-6 外觀：臉色蒼白，五官端正，頭髮凌亂。身高約180，身材纖細。 語言： 國/台 照顧者：看護（醫院的） 對話情境 第一次治療將結束前，治療師在詢問病人目前生活的狀況最想要改善之處，要做為治療目標。病人在二週前缺血性中風，行動並不方便，但似乎不太喜歡坐輪椅移動。 需要同理的狀況 不滿的情緒十分強烈 練習目標 練習如何應對表達出強烈的負面情緒的病人。 對話內容 T：治療師 P：病人...</p></div><footer class=entry-footer><span title='2022-11-10 09:46:22 +0800 +0800'>November 10, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 同理心課堂練習要素" href=https://juyujeng.github.io/researchlife/blog/research/practice_script_for_empathy/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://juyujeng.github.io/researchlife/images/med%20situation%203.excalidraw.svg alt></figure><header class=entry-header><h2>同理課程的困難</h2></header><div class=entry-content><p>規畫的同理心訓練課程在經過幾次的試驗之後大致上已經完成
課程粗略可以分為兩個部份，一個是同理心相關的知識介紹，另一個則是同理心實務技巧的練習
知識的介紹這邊沒有什麼問題，而且對於表現同理心為什麼會是困難的一件事情我相信我可以解釋地很清楚
困難的是在同理心實務技巧的練習
需要掌握的原則和技巧說起來其實都不難
但是這些技巧的使用就像身體技能一般，光說不練是沒有辦法讓身體習慣怎麼進行的
雖然透過之前實習生的錄音逐字稿可以截取出讓學員們看著練習的腳本
但幾次的試教下來我覺得看著文字的腳本練習，效果感覺沒有很好
雖然說大家都可以給出不錯的回應，但也感覺得出來大家其實並沒有非常能融入腳本的情境當中
這種帶著半抽離感的情境，總覺得可能離現實很遙遠
會不會實際來拍攝練習題目的影片效果會比較好呢？</p></div><footer class=entry-footer><span title='2022-10-31 21:15:20 +0800 +0800'>October 31, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 同理課程的困難" href=https://juyujeng.github.io/researchlife/blog/research/class-practice/></a></article><article class=post-entry><header class=entry-header><h2>potential nonverbal cues</h2></header><div class=entry-content><p>list of potential nonverbal cues</p></div><footer class=entry-footer><span title='2022-10-25 00:00:00 +0000 UTC'>October 25, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to potential nonverbal cues" href=https://juyujeng.github.io/researchlife/blog/research/potential-nonverbal-cues/></a></article><article class=post-entry><header class=entry-header><h2>Relation between subdimensions of empathy</h2></header><div class=entry-content><p>常見的同理心的向度 同理心的定義中曾提到，同理心的的定義多元，目前普遍接受同理心是一個包含多元向度（多元能力）的概念（或是能力）。
在這樣子的看法底下，我很自然地認為，這些不同的次向度的能力應該彼此之間是正相關的，因為都被一個共通的潛在構念所影響（圖二左）。
同理心是一個包含多向度的潛在構念或是一個籠統名詞呢？ 不過，Klöckner等人（2022）的研究卻發現，認知上的同理（JSE測量）跟行為上的同理表現（以VR-CODES測量）只有部份相關。更明確地說，JSE的分數高低的差異，只在醫師（實習生）的非口語行為表現上看到差異，口語同理行為則和JSE分數高低無關。
如果這些不同的次向度之間的關係並不是那麼緊密的話，也許同理心比較像是一種籠統的名詞（collective term），將許多不同的能力籠統地括在一起說（圖二右）。這些不同的能力之間不必然有正相關。
如果是這樣子的話，那麼要測量同理心將會更加的困難，因為不同的能力之間如果不一定有關係的話，那麼就沒有辦法只測量其中一項能力而去推估其他能力，這樣就不同測那麼多不同的次能力；相反的，可能要測量許多不同的能力，才可以形成對於同理心能力的印象。
不過，Klöckner等人（2022）只有15個人的資料，樣本數其實很少，這個結果是否是穩定的還需要更多的研究。只是，現有的同理心測量，絕大多數都是自評的認知同理。要有更多探討不同的同理向度間的關係，可能還要有較有效的情緒同理、行為同理的測量工具出現。
參考文獻 Klöckner, C. C., Gerbase, M. W., Nendaz, M., Baroffio, A., & Junod, N. P. (2022). Relationship between self-reported cognitive and behavioural empathy among medical students. Patient Education and Counseling, 105(4), 895–901. https://doi.org/10.1016/j.pec.2021.07.053</p></div><footer class=entry-footer><span title='2022-09-23 00:00:00 +0000 UTC'>September 23, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to Relation between subdimensions of empathy" href=https://juyujeng.github.io/researchlife/blog/research/relation-between-subdimensions-of-empathy/></a></article><article class=post-entry><header class=entry-header><h2>同理的困難</h2></header><div class=entry-content><p>同理的困難 make other understand 要做到同理有許多的困難
要先體認到不同的人有不同的角度與觀點，所以會有不同的看法以及預期。 在互動的過程需要理解或是辨認出他人現在的想法或是感受是什麼？ 除了理解到他人現在的想法外，還要理解對方「為什麼」會這麼想。能夠從對方的觀點來思考。才可以知道衝突發生的徵結點。 在可以從對方的觀點來思考之後，你才有辦法選擇以及做出適當反應。因為你要考量到反應之後，對方可能有什麼樣的反應。 每一步，都需要假設性思考、推理的能力。這都不是簡單的事情，以下再進一步說明
知道每個人都是不一樣的 每個人都是不一樣的，每個人都知道，但卻很常忘掉。又或者是說，我們可能很常用其他的方法來解釋其他人和我們的不一樣。
我這邊的不一樣指的是觀點的不同。這個不同有兩種來源，一個是較長期穩定的，基於每個人的成長背景、知識，以及長期和這個世界互動後形成對於世界認識的基模或者是習慣，這些組合成我們看待世界的觀點，影響著我們對於看到的東西所做出的詮釋以及思考歷程。另一個是個人當下的狀態，情緒、身體狀況（例如身體某個部位在痛、昨晚沒睡飽），也會影響當下對世界的看法，以及如果和世界互動的選擇。如果用數學式來看的話，也許會是像這樣吧
$$現在看世界的觀點 = 長期養成的觀點 + 當下的狀態$$
基於上述理由，對於同樣的事情不同的人有著不同的觀點或是感受，是很正常的，因為每個人的背景知識不一樣，當下的身體狀況也可能不一樣。
就像是上圖中的第一格，兩個人從各自不同的觀點來看同一個事物，一邊看起來是9，而另一邊看起來是6。如果雙方不知道彼此的觀點有所不同，那麼很容易都認為對方應該也要看到和自己相同的數字。甚至在發現對方和自己看得不一樣時，會覺得對方一定是錯的，或是對方有問題，才會和自己不一樣。
知道其他人可能和自己不同，才保有雙方繼續互動下去的彈性，否則在發現對方所想的和自己心裡所想的有所不同時，先入為主的認為對方有問題，接下來如果需要雙方達成共識，是接近不可能的事情。
理解或是辨認出他人現在的想法或是感受 在明白每個人的觀點都可能有所不同之後，接下來便是要實際理解到底對方的想法是什麼？畢竟許多人是有經過社會化的，外顯出來的和內心所想的不一定會相同。而在醫療的領域當中，有時候會遇到的情況是病人受限於身體狀況，可能也很難將自己的想法或是感受表達地很清楚。有些時候需要藉由一些身體語言或是引導問答，才有辦法釐清。那才有辦法像圖中第2格一樣，掌握到對方從他的角度看到的數字，是6。
理解對方「為什麼」會這麼想 光是知道對方現在實際的想法或是感受，那只是同理的初步動作。去理解到對方「為什麼」會有這樣的想法或是感受，我認為才算是進到的同理的核心。因為這必須要跳出自己的思考的角度和框架，試著從別人的角度去思考。這需要一些抽象推理能力，或是想像力，才有辦法將自己想像為他人，用另一套看世界的方法來思考。
不過，若是自己曾有過切身經驗，也許會比較簡單，但也可能有反效果。因為若對方和自己在相似的經驗當中是依循著相同的思考模式的話，你可能便可以理解對方為什麼會這麼想。但，每個人在面對相同的事件是可能有不同的反應或是思考模式的。甚至是雖然有相同的反應，但思考模式是完全不同的。
因此，這個部份是同理過程當中相當重要，但也十分困難的一步。若跟對方沒有基本的認識，基本上是很難有辦法去理解到對方為什麼會有這樣子的想法或是感受，只能夠從自己過去的經驗或是知識來去做猜測（要冒著猜錯的風險）。
做出適當反應 如果做到了上一步，那麼便自然而然的可以去做出適當的反應。
就像是圖中第3格，我們理解到對方之所以會將數字看作是6，是因為他從他的角度來看就會是6。而且他似乎沒有注意到數字上有一條底線，顯示9可能才是這個數字的正確答案。
如果知道對方是因為角度的關係，並且可能忽略掉了細微的底線。這時可以邀請對方到我這邊來，並指出底線的存在。又或者是我幫對方將數字掉頭，讓他可以看清楚底線。如果再多考慮到對方受傷行動不便（我應該有畫得很明顯吧？），後面這個做法會是更好的做法。
當還沒有辦法完成上一步，理解對方為什麼會這麼想時，最好不要輕舉妄動，這時最佳的行為準則是想辦法獲得更多的訊息來幫助自己理解對方的思考模式。</p></div><footer class=entry-footer><span title='2022-09-14 00:00:00 +0000 UTC'>September 14, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to 同理的困難" href=https://juyujeng.github.io/researchlife/blog/research/%E5%90%8C%E7%90%86%E7%9A%84%E5%9B%B0%E9%9B%A3/></a></article><article class=post-entry><header class=entry-header><h2>OT學生的同理等級：文獻閱讀心得 2</h2></header><div class=entry-content><p>OT學生的同理等級：文獻閱讀心得 2 繼昨天看到的那篇Brown等人（2010）的文章後，今天看到一篇非常類似的文章。Serrada-Tejeda等人（2022）在西班牙的大學中等於是重覆了這個研究，他們廣發量表（[[Jefferson Scale of Empathy]]以及[[interpersonal reactivity inventory]]，這兩個都是常見的自評同理心量表），同樣以橫斷性研究的方式來檢驗大學四年的OT訓練是否會影響OT學生們的自評同理程度。
不過這次Serrada-Tejeda等人有221名有效樣本，比起Brown他們只有92位真得是好太多了。而且四個年級的學生都有（一到四年級分別有71、54、46、50人）。不過大部份仍然是女性（88.2％）。
Serrada-Tejeda他們的結果和Brown一樣，四個年級的學生的自評同理心並沒有差異，而且得分和過去文獻中回報的比起來，這個大學的OT學生的自評同理程度算是高的。
而與Brown等人的研究不同的是，這次Serrada-Tejeda他們有發現性別的差異，女性自評同理程度比較高。但這並不是新聞，許多其他的研究其實都有發現女性的同理心分數通常比男性高。Brown等人的研究沒有得到這個結果應該是人太少吧。
這篇研究的分析結果比起Brown他們寫得再多了一點點，至少有附上表格，可以比較清楚的看到四個年級的得分。
心得與發想 連續看到兩篇OT學生的學校訓練年資與自評同理程度無關的文章，會有這種結果其實有三種可能。第一個可能是這些訓練無助於同理心的增長；而第二種可能是學校訓練有用，但使用的測量工具測量不到學校訓練所增進的同理心；而第三種就是訓練無助同理心，而測量工具也測不到同理心。
第一種可能其實挺有可能的，畢竟主要的學校訓練和治療相關的專業知識比較有關係，同理心相關技巧不一定有在課程之中，文獻當中也沒有詳細說明。
第二種可能則是工具的問題，雖然說兩篇研究都是用目前常見的同理心自評量表，但其實仔細看題目，實在是會有點問號，像是JSE當中有一題：
I believe that emotion has no place in the treatment of medical illness
這個像是在測量醫事人員本身的信念，而不是能力。或是像另一題，同樣對於是否能測量到同理心打一個問號：
I have a good sense of humor that I think contributes to a better clinical outcome
因此，如果有更適合的工具可以使用的話，也許可以試著在台灣也來做一個調查試試看。而且這個調查若同時可以比較醫學院的其他科系，同時看看不同的醫學院內科系訓練對於學生們的同理心是否有所幫助，會是很有趣的議題。因為目前國外就已經有用JSE在不同科系進行過研究，有的有發現會隨著訓練年資同理心上升，而有的發現隨著訓練年資同理心下降。也許不同科系的訓練真的有所不同。例如工作上面和病人接觸時間較短的醫技系、藥學系的訓練，也許真的就和其他跟病人接觸時間較長的科系如護理系、醫學系，所強調同理心的程度不一樣，訓練也就不一樣。
文獻 Brown, T., Williams, B., Boyle, M., Molloy, A., McKenna, L., Molloy, L., & Lewis, B. (2010). Levels of empathy in undergraduate occupational therapy students....</p></div><footer class=entry-footer><span title='2022-09-01 00:00:00 +0000 UTC'>September 1, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to OT學生的同理等級：文獻閱讀心得 2" href=https://juyujeng.github.io/researchlife/blog/research/ot%E5%AD%B8%E7%94%9F%E7%9A%84%E5%90%8C%E7%90%86%E7%AD%89%E7%B4%9A%E6%96%87%E7%8D%BB%E9%96%B1%E8%AE%80%E5%BF%83%E5%BE%97-2/></a></article><article class=post-entry><header class=entry-header><h2>glmmTMB vs. GLMMadaptive</h2></header><div class=entry-content><p>glmmTMB vs. GLMMadaptive 記錄一下分析資料時使用glmmTMB以及GLMMadaptive的心得
glmmTMB GLMMadaptive 估計方法 Laplace approximation adaptive Gauss-Hermite quadrature 預測值 可以進行單純count part預測、zero part預測，以及兩部份模型加起來的期望值預測 沒辦法只進行count part預測，只能做zero part預測，以及兩部份模型加起來的期望值預測 估計方法的差異在本次zero-inflated model使用過程中有很大的使用經驗差異。glmmTMB比較常出現convergent problem，而GLMMadaptive幾乎沒有。根據glmmTMB的troubleshooting說明，會出現問題主要是和random effect有關，如果拿掉zero part random intercept就不會再跳出錯誤訊息了。而根據GLMMadaptive做的模型比較，有沒有zero part random intercept其實沒有顯著的差異。因此如果不強求一定要納入zero part random intercept，兩個packages的結果是一致的。不過如果一定要納入zero part random intercept，那就只能使用GLMMadaptive才不會有錯誤警告出現。
兩個套件的另一個差異是在進行預測（predict）時，glmmTMB可以只根據count part的結果進行預測，而GLMMadaptive不行。會有這個需求是因為很常只有count part的預測變項有顯著的結果，但是zero part沒有顯著的預測變項，因此若只想要看count part的預測線時，GLMMadaptive沒辦法給我這個結果1。
文獻上討論Laplace approximation和adaptive Gauss-Hermite quadrature哪一種估計方法比較準的有好幾篇，我大概看了一下他們的結論，其實不同研究的結果並不一致2。
另一個使用上的差異是在安裝上，GLMMadaptive安裝比較沒有什麼問題。但是glmmTMB因為還需要TMB，有時候在更新套件時會有版本不一致的情況，有點小困擾。
也許emmeans::qdgr()可以，但需要試試看 ↩︎
不過glmmTMB的作者在他的網頁上提到，Gauss-Hermite quadrature比Laplace approximation還要準確，但是估計速度比較慢（但在我的資料感覺不出來），而且random effect的數量上限制比較多。 ↩︎</p></div><footer class=entry-footer><span title='2022-08-31 00:00:00 +0000 UTC'>August 31, 2022</span>&nbsp;·&nbsp;Ju</footer><a class=entry-link aria-label="post link to glmmTMB vs. GLMMadaptive" href=https://juyujeng.github.io/researchlife/blog/research/glmmtmb-vs.-glmmadaptive/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://juyujeng.github.io/researchlife/blog/research/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>contact me @ <a href="mailto: juyujeng@gmail.com">juyujeng@gmail.com</a></span><br><span>&copy; 2023 <a href=https://juyujeng.github.io/researchlife/>Ju' Research and Life</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>